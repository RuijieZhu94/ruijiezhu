---
permalink: /
title: "Ruijie Zhu 朱睿杰"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## Biography
------

I am currently a postgraduate student working with Prof. [Yongdong Zhang](https://scholar.google.com/citations?user=hxGs4ukAAAAJ&hl) and Prof. [Tianzhu Zhang](http://staff.ustc.edu.cn/~tzzhang/) at University of Science and Technology of China (USTC). I got the B.Eng. degree in Computer Science and Technology at Northwestern Polytechnical University (NWPU) in 2022, under the guidance of Prof. [Yuchao Dai](https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl).

My research interest includes Depth estimation, 3D reconstruction, and Nerual rendering. 

**I am looking for a Ph.D. position (25 Fall) in 3D vision, feel free to contact me at ruijiezhu@mail.ustc.edu.cn.**

## Recent News
------

<div style="border: 1px solid #ddd; padding: 10px; height: 200px; overflow-y: scroll;">
  <ul>
    <li>Sep. 2024: <a href="https://arxiv.org/abs/2409.02494">Plane2Depth</a> was released on arXiv.</li>
    <li>Jul. 2024: <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth</a> was released on arXiv.</li>
    <li>Dec. 2023: <a href="https://arxiv.org/abs/2312.09527">TI-Face</a> was released on arXiv.</li>
    <li>Nov. 2023: <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023">HA-Bins</a> was accepted by TCSVT.</li>
    <li>Oct. 2023: <a href="https://ruijiezhu94.github.io/ECDepth_page">EC-Depth</a> was released on arXiv.</li>
    <li>Oct. 2023: I got the <strong>1st place</strong> in ICCV 2023 workshop <a href="https://sites.google.com/view/vschh/home">To NeRF or not to NeRF: A View Synthesis Challenge for Human Heads</a>. <a href="https://openaccess.thecvf.com/content/ICCV2023W/RHWC/papers/Jang_VSCHH_2023_A_Benchmark_for_the_View_Synthesis_Challenge_of_ICCVW_2023_paper.pdf">[paper]</a> <a href="https://youtu.be/QRuVvtpoeVM">[video]</a></li>
    <li>June 2023: I got the <strong>1st place</strong> on RoboDepth competition <a href="https://codalab.lisn.upsaclay.fr/competitions/9418#results">Track1</a> (self-supervised monocular depth estimation) and the <strong>2nd place</strong> on <a href="https://codalab.lisn.upsaclay.fr/competitions/9821#results">Track2</a> (fully-supervised monocular depth estimation) in ICRA 2023. <a href="https://arxiv.org/pdf/2307.15061">[paper]</a> <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767">[video]</a></li>
    <li>Oct. 2022: I got <strong>2nd place</strong> on Monocular Depth Estimation leaderboard in ECCV2022 workshop: <a href="http://www.robustvision.net/leaderboard.php?benchmark=depth">Robust Vision Challenge 2022</a>. <a href="https://youtu.be/8ZwiSUYNJiI">[video]</a></li>
  </ul>
</div>


## Experiences
------

- Sept. 2018 - July. 2022, Undergradute, Honors College, NWPU
<!-- - July.2019 - Aug.2019, Visiting Student, University of Oxford -->
- July. 2020 - Sept. 2020, Software Development Intern, Huawei
<!-- - April.2021 - July.2021, Reinforcement Learining Research Online, University of Cambridge -->
- Sept. 2022 - Now, Postgraduate, USTC
- Jan. 2024 - Apr. 2024, Algorithm devolopment intern, SenseTime Inc.
- Aug. 2024 - Now, Research intern, Shanghai AILab


<div class="logo" style="display: flex; justify-content: space-around; align-items: center;">
  <a href="https://en.nwpu.edu.cn/"><img src="images/logo_NWPU.png" alt="NWPU" style="height: 100px; width: auto;"></a>
  <a href="https://www.huawei.com/en/"><img src="images/logo_HUAWEI.jpeg" alt="HUAWEI" style="height: 100px; width: auto;"></a>
  <a href="https://en.ustc.edu.cn/"><img src="images/logo_USTC.png" alt="USTC" style="height: 100px; width: auto;"></a>
  <a href="https://www.sensetime.com/"><img src="images/logo_SenseTime.png" alt="SenseTime" style="height: 100px; width: auto;"></a>
  <a href="https://www.shlab.org.cn/"><img src="images/logo_AILab.jpeg" alt="AILab" style="height: 100px; width: auto;"></a>
</div>


## Publications
------

\* denotes equal contribution. More publications can be found in <a href="https://scholar.google.com/citations?user=6uuAEdkAAAAJ&hl=en">Google Scholar</a>.


<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-plane2depth.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/Plane2Depth">Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation</a>
      <br>Li Liu*, <b>Ruijie Zhu*</b>, Jiacheng Deng, Ziyang Song, Wenfei Yang, Tianzhu Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2409.02494">[Paper]</a>
      <!-- <a href="https://ruijiezhu94.github.io/Plane2Depth">[Webpage]</a> -->
      <a href="https://github.com/RuijieZhu94/mmdepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-ScaleDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth: Decomposing Metric Depth Estimation into Scale Prediction and Relative Depth Estimation</a>
      <br><b>Ruijie Zhu</b>, Chuxin Wang, Ziyang Song, Li Liu, Tianzhu Zhang, Yongdong Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2407.08187">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ScaleDepth">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://github.com/RuijieZhu94/TI-Face">TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</a>
      <br><b>Ruijie Zhu</b>, Jiahao Chang, Ziyang Song, Jiahuan Yu, Tianzhu Zhang
      <br> 1st place solution in the View Synthesis Challenge for Human Heads (VSCHH) @ ICCV, 2023
      <br> 
      <a href="https://arxiv.org/abs/2312.09527">[Paper]</a>
      <a href="https://youtu.be/QRuVvtpoeVM">[Video]</a>
      <a href="https://github.com/RuijieZhu94/TI-Face">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-arxiv-ECDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ECDepth_page/">EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes</a>
      <br>Ziyang Song*, <b>Ruijie Zhu*</b>, Chuxin Wang, Jiacheng Deng, Jianfeng He, Tianzhu Zhang
      <br> ArXiv, 2023
      <br> 
      <a href="http://arxiv.org/abs/2310.08044">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ECDepth_page/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/EC-Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-tcsvt-HABins.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation across Multiple Datasets</a>
      <br><b>Ruijie Zhu</b>, Ziyang Song, Li Liu, Jianfeng He, Tianzhu Zhang, Yongdong Zhang
      <br> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10325550">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/HABins">[Code]</a>
    </td>
  </tr>


</table>

## Talks
------

- [TIFace: Improving Tensorial Radiance Field and Implicit Surfaces for Face Reconstruction](https://ruijiezhu94.github.io/ruijiezhu/talks/2023-10-02-talk), ICCV, 2023
- [IRUDepth: Improve Robustness and Uncertainty of Self-Supervised Monocular Depth Estimation](https://ruijiezhu94.github.io/ruijiezhu/talks/2023-05-30-talk-1), ICRA, 2023
- [MixBins: Group-wise Bins for Robust Monocular Depth Estimation via Mixing Datasets](https://ruijiezhu94.github.io/ruijiezhu/talks/2022-10-23-talk), ECCV, 2022

## Awards
------

- Wuyajun Scholarship & first class scholarship of NWPU, 2019
- Wuyajun Scholarship & first class scholarship of NWPU, 2020
- CATIC Scholarship(The highest honor for graduates, <1%) & first class scholarship of NWPU, 2021
- Outstanding Graduate of NWPU, 2022
- USTC-Suzhou Industrial Park Scholarship & first class scholarship of USTC, 2023
- Deep Space Exploration Scholarship, 2024

## Posts
------

- VALSE•2021 meeting record. [[Yuque]](https://www.yuque.com/docs/share/99290803-dfd7-4343-9ee6-0887f10bcec0?#) [[Zhihu]](https://zhuanlan.zhihu.com/p/422911676)
- Course Notes of Statistical Learning course in USTC. [[Git repo]](https://github.com/RuijieZhu94/StatisticalLearning_USTC) [[Zhihu]](https://www.zhihu.com/question/49386395/answer/3121492954) [[PDF]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/outline.pdf)
 [[Abstract]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/cheatsheet.pdf)

## Others
------

- Reviewer: ICRA 2023


<!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM"></script> -->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM'></script>
