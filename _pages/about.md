---
permalink: /
title: "Ruijie Zhu 朱睿杰"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

Biography
------

I am currently a postgraduate student working with Prof. [Yongdong Zhang](https://scholar.google.com/citations?user=hxGs4ukAAAAJ&hl) and Prof. [Tianzhu Zhang](http://staff.ustc.edu.cn/~tzzhang/) at University of Science and Technology of China (USTC). I got the B.Eng. degree in Computer Science and Technology at Northwestern Polytechnical University (NWPU) in 2022, under the guidance of Prof. [Yuchao Dai](https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl).

My research interest includes Depth estimation, 3D reconstruction, and Nerual rendering. 

**I am looking for a Ph.D. position (25 Fall) in 3D vision, feel free to contact me at ruijiezhu@mail.ustc.edu.cn.**

Recent News
------
- Sep. 2024: [Plane2Depth](https://arxiv.org/abs/2409.02494) was released on arXiv.
- Jul. 2024: [ScaleDepth](https://ruijiezhu94.github.io/ScaleDepth) was released on arXiv.
- Dec. 2023: [TI-Face](https://arxiv.org/abs/2312.09527) was released on arXiv.
- Nov. 2023: [HA-Bins](https://ruijiezhu94.github.io/HABins_TCSVT2023) was accepted by TCSVT.
- Oct. 2023: [EC-Depth](https://ruijiezhu94.github.io/ECDepth_page) was released on arXiv.
- Oct. 2023: I got the **1st place** in ICCV 2023 workshop [To NeRF or not to NeRF: A View Synthesis Challenge for Human Heads](https://sites.google.com/view/vschh/home). [[paper]](https://openaccess.thecvf.com/content/ICCV2023W/RHWC/papers/Jang_VSCHH_2023_A_Benchmark_for_the_View_Synthesis_Challenge_of_ICCVW_2023_paper.pdf) [[video]](https://youtu.be/QRuVvtpoeVM)
- June. 2023: I got the **1st place** on RoboDepth competition [Track1](https://codalab.lisn.upsaclay.fr/competitions/9418#results) (self-supervised monocular depth estimation) and the **2nd place** on [Track2](https://codalab.lisn.upsaclay.fr/competitions/9821#results) (fully-supervised monocular depth estimation) in ICRA 2023. [[paper]](https://arxiv.org/pdf/2307.15061) [[video]](https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767)
- Oct. 2022: I got **2nd place** on Monocular Depth Estimation leaderboard in ECCV2022 workshop: [Robust Vision Challenge 2022](http://www.robustvision.net/leaderboard.php?benchmark=depth). [[video]](https://youtu.be/8ZwiSUYNJiI)

Experiences
------
- Sept. 2018 - July. 2022, Undergradute, Honors College, NWPU
<!-- - July.2019 - Aug.2019, Visiting Student, University of Oxford -->
- July. 2020 - Sept. 2020, Software Development Intern, Huawei
<!-- - April.2021 - July.2021, Reinforcement Learining Research Online, University of Cambridge -->
- Sept. 2022 - Now, Postgraduate, USTC
- Jan. 2024 - Apr. 2024, Algorithm devolopment intern, SenseTime Inc.
- Aug. 2024 - Now, Research intern, Shanghai AILab


<div class="logo" style="display: flex; justify-content: space-around; align-items: center;">
  <a href="https://en.nwpu.edu.cn/"><img src="images/logo_NWPU.png" alt="NWPU" style="height: 100px; width: auto;"></a>
  <a href="https://www.huawei.com/en/"><img src="images/logo_HUAWEI.jpeg" alt="HUAWEI" style="height: 100px; width: auto;"></a>
  <a href="https://en.ustc.edu.cn/"><img src="images/logo_USTC.png" alt="USTC" style="height: 100px; width: auto;"></a>
  <a href="https://www.sensetime.com/"><img src="images/logo_SenseTime.png" alt="SenseTime" style="height: 100px; width: auto;"></a>
  <a href="https://www.shlab.org.cn/"><img src="images/logo_AILab.png" alt="AILab" style="height: 100px; width: auto;"></a>
</div>


<!-- Publications
------
- 2023
7. R. Zhu, Z. Song, L. Liu, J. He, T. Zhang and Y. Zhang, "HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation across Multiple Datasets," in IEEE Transactions on Circuits and Systems for Video Technology, doi: 10.1109/TCSVT.2023.3335316.
6. Zhu R, Song Z, Wang C, et al. EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes[J]. arXiv preprint arXiv:2310.08044, 2023.
5. Jang Y, Zheng J, Song J, et al. VSCHH 2023: A Benchmark for the View Synthesis Challenge of Human Heads[C]//Proceedings of the IEEE/CVF International Conference on Computer Vision. 2023: 1121-1128.
4. Kong L, Niu Y, Xie S, et al. The RoboDepth Challenge: Methods and Advancements Towards Robust Depth Estimation[J]. arXiv preprint arXiv:2307.15061, 2023.
- Before 2022
3. Z. Xu, Y. Jiang, G. Li and R. Zhu, "ASMOD: Adaptive Saliency Map on Object Detection," 2022 IEEE 10th International Conference on Information, Communication and Networks (ICICN). IEEE, 2022: 524-529.
2. Xu C, Zhu R, Yang D. Karting racing: A revisit to PPO and SAC algorithm[C]//2021 International Conference on Computer Information Science and Artificial Intelligence (CISAI). IEEE, 2021: 310-316.
1. Zhu R, Fan C, Chen Z, et al. Bio-invasion: A prediction model based on multi-objective optimization[C]//2021 IEEE International Conference on Signal Processing, Communications and Computing (ICSPCC). IEEE, 2021: 1-5.

Patents
------
1. 戴玉超, 朱睿杰, 项末初,等. 基于深度学习的Android手机端侧AR交互系统[p]. 中国, CN115309301A, 2022. -->

Publications
------

\* denotes equal contribution. More publications can be found in <a href="https://scholar.google.com/citations?user=6uuAEdkAAAAJ&hl=en">Google Scholar</a>.


<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-plane2depth.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/Plane2Depth">Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation</a>
      <br>Li Liu*, <b>Ruijie Zhu*</b>, Jiacheng Deng, Ziyang Song, Wenfei Yang, Tianzhu Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2409.02494">[Paper]</a>
      <!-- <a href="https://ruijiezhu94.github.io/Plane2Depth">[Webpage]</a> -->
      <a href="https://github.com/RuijieZhu94/mmdepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-ScaleDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth: Decomposing Metric Depth Estimation into Scale Prediction and Relative Depth Estimation</a>
      <br><b>Ruijie Zhu</b>, Chuxin Wang, Ziyang Song, Li Liu, Tianzhu Zhang, Yongdong Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2407.08187">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ScaleDepth">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://github.com/RuijieZhu94/TI-Face">TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</a>
      <br><b>Ruijie Zhu</b>, Jiahao Chang, Ziyang Song, Jiahuan Yu, Tianzhu Zhang
      <br> 1st place solution in the View Synthesis Challenge for Human Heads (VSCHH) @ ICCV, 2023
      <br> 
      <a href="https://arxiv.org/abs/2312.09527">[Paper]</a>
      <a href="https://youtu.be/QRuVvtpoeVM">[Video]</a>
      <a href="https://github.com/RuijieZhu94/TI-Face">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-arxiv-ECDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ECDepth_page/">EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes</a>
      <br>Ziyang Song*, <b>Ruijie Zhu*</b>, Chuxin Wang, Jiacheng Deng, Jianfeng He, Tianzhu Zhang
      <br> ArXiv, 2023
      <br> 
      <a href="http://arxiv.org/abs/2310.08044">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ECDepth_page/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/EC-Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-tcsvt-HABins.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation across Multiple Datasets</a>
      <br><b>Ruijie Zhu</b>, Ziyang Song, Li Liu, Jianfeng He, Tianzhu Zhang, Yongdong Zhang
      <br> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10325550">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/HABins">[Code]</a>
    </td>
  </tr>


</table>

<!-- Talks
------
- [TIFace: Improving Tensorial Radiance Field and Implicit Surfaces for Face Reconstruction](https://ruijiezhu94.github.io/ruijiezhu/talks/2023-10-02-talk), ICCV, 2023
- [IRUDepth: Improve Robustness and Uncertainty of Self-Supervised Monocular Depth Estimation](https://ruijiezhu94.github.io/ruijiezhu/talks/2023-05-30-talk-1), ICRA, 2023
- [MixBins: Group-wise Bins for Robust Monocular Depth Estimation via Mixing Datasets](https://ruijiezhu94.github.io/ruijiezhu/talks/2022-10-23-talk), ECCV, 2022 -->

Awards
------
- Wuyajun Scholarship & first class scholarship of NWPU, 2019
- Wuyajun Scholarship & first class scholarship of NWPU, 2020
- CATIC Scholarship(The highest honor for graduates, <1%) & first class scholarship of NWPU, 2021
- Outstanding Graduate of NWPU, 2022
- USTC-Suzhou Industrial Park Scholarship & first class scholarship of USTC, 2023
- Deep Space Exploration Scholarship, 2024

Others
------
- Reviewer: ICRA 2023


<!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM"></script> -->
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM'></script>
