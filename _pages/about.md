---
permalink: /
title: "Ruijie Zhu 朱睿杰"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## Biography

I am currently a postgraduate student working with Prof. [Yongdong Zhang](https://scholar.google.com/citations?user=hxGs4ukAAAAJ&hl) and Prof. [Tianzhu Zhang](http://staff.ustc.edu.cn/~tzzhang/) at University of Science and Technology of China (USTC). I got the B.Eng. degree in Computer Science and Technology at Northwestern Polytechnical University (NWPU) in 2022, under the guidance of Prof. [Yuchao Dai](https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl).

My research interest includes Depth estimation, 3D reconstruction, and Neural rendering. 

## Recent News

<div style="border: 1px solid #ddd; padding: 10px; height: 200px; overflow-y: scroll;">
  <ul>
    <li>Jan. 2025: <a href="https://indu1ge.github.io/DepthMaster_page/">DepthMaster</a> was released on arXiv.</li>
    <li>Oct. 2024: <a href="https://ruijiezhu94.github.io/plane2depth_page/">Plane2Depth</a> was accepted by TCSVT.</li>  
    <li>Sep. 2024: Two papers <a href="https://ruijiezhu94.github.io/MotionGS_page">MotionGS</a> and <a href="https://arxiv.org/abs/2410.13607">DN-4DGS</a> were accepted by NeurIPS 2024.</li>
    <li>Jul. 2024: <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth</a> was released on arXiv.</li>
    <li>Dec. 2023: <a href="https://arxiv.org/abs/2312.09527">TI-Face</a> was released on arXiv.</li>
    <li>Nov. 2023: <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023">HA-Bins</a> was accepted by TCSVT.</li>
    <li>Oct. 2023: <a href="https://ruijiezhu94.github.io/ERDepth_page">EC-Depth</a> was released on arXiv.</li>
    <li>Oct. 2023: I got the <strong>1st place</strong> in ICCV 2023 workshop <a href="https://sites.google.com/view/vschh/home">To NeRF or not to NeRF: A View Synthesis Challenge for Human Heads</a>. <a href="https://openaccess.thecvf.com/content/ICCV2023W/RHWC/papers/Jang_VSCHH_2023_A_Benchmark_for_the_View_Synthesis_Challenge_of_ICCVW_2023_paper.pdf">[paper]</a> <a href="https://youtu.be/QRuVvtpoeVM">[video]</a></li>
    <li>June 2023: I got the <strong>1st place</strong> on RoboDepth competition <a href="https://codalab.lisn.upsaclay.fr/competitions/9418#results">Track1</a> (self-supervised monocular depth estimation) and the <strong>2nd place</strong> on <a href="https://codalab.lisn.upsaclay.fr/competitions/9821#results">Track2</a> (fully-supervised monocular depth estimation) in ICRA 2023. <a href="https://arxiv.org/pdf/2307.15061">[paper]</a> <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767">[video]</a></li>
    <li>Oct. 2022: I got <strong>2nd place</strong> on Monocular Depth Estimation leaderboard in ECCV2022 workshop: <a href="http://www.robustvision.net/leaderboard.php?benchmark=depth">Robust Vision Challenge 2022</a>. <a href="https://youtu.be/8ZwiSUYNJiI">[video]</a></li>
  </ul>
</div>


## Experiences

- Sept. 2018 - July. 2022, Undergradute, Honors College, NWPU
<!-- - July.2019 - Aug.2019, Visiting Student, University of Oxford -->
<!-- - July. 2020 - Sept. 2020, Software Development Intern, Huawei -->
<!-- - April.2021 - July.2021, Reinforcement Learining Research Online, University of Cambridge -->
- Sept. 2022 - Now, Postgraduate, USTC
<!-- - Jan. 2024 - Apr. 2024, Algorithm devolopment intern, SenseTime Inc. -->
- Aug. 2024 - Mar. 2025, Research intern, Shanghai Pujiang Lab
- May. 2025 - Now, Research intern, Tencent ARC Lab


<div class="logo" style="display: flex; justify-content: space-around; align-items: center;">
  <a href="https://en.nwpu.edu.cn/"><img src="images/logo_NWPU.png" alt="NWPU" style="height: 100px; width: auto;"></a>
  <!-- <a href="https://www.huawei.com/en/"><img src="images/logo_HUAWEI.jpeg" alt="HUAWEI" style="height: 100px; width: auto;"></a> -->
  <a href="https://en.ustc.edu.cn/"><img src="images/logo_USTC.png" alt="USTC" style="height: 100px; width: auto;"></a>
  <!-- <a href="https://www.sensetime.com/"><img src="images/logo_SenseTime.png" alt="SenseTime" style="height: 100px; width: auto;"></a> -->
  <a href="https://www.shlab.org.cn/"><img src="images/logo_AILab.jpeg" alt="Shanghai AILab" style="height: 100px; width: auto;"></a>
  <a href="https://arc.tencent.com/en/index"><img src="images/logo_ARCLab.png" alt="Tencent ARCLab" style="height: 100px; width: auto;"></a>
</div>


## Publications


\* denotes equal contribution. More publications can be found in <a href="https://scholar.google.com/citations?user=6uuAEdkAAAAJ&hl=en">Google Scholar</a>.


<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2025-arxiv-depthmaster.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://indu1ge.github.io/DepthMaster_page/">DepthMaster: Taming Diffusion Models for Monocular Depth Estimation</a>
      <br>Ziyang Song*, Zerong Wang*, Bo Li, Hao Zhang, <b>Ruijie Zhu</b>, Li Liu, Peng-Tao Jiang, Tianzhu Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2501.02576">[Paper]</a>
      <a href="https://indu1ge.github.io/DepthMaster_page/">[Webpage]</a>
      <a href="https://github.com/indu1ge/DepthMaster">[Code]</a>
      <a href="https://huggingface.co/zysong212/DepthMaster">[Model]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-motiongs.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/MotionGS_page">MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</a>
      <br><b>Ruijie Zhu*</b>, Yanzhe Liang*, Hanzhi Chang, Jiacheng Deng, Jiahao Lu, Wenfei Yang, Tianzhu Zhang, Yongdong Zhang
      <br> NeurIPS, 2024
      <br> 
      <a href="https://arxiv.org/abs/2410.07707">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/MotionGS_page">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/MotionGS">[Code]</a>
      <a href="https://www.youtube.com/watch?v=25DgViuuKFI">[Video]</a>
    </td>
  </tr>


  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-dn4dgs.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://arxiv.org/abs/2410.13607">DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering</a>
      <br>Jiahao Lu, Jiacheng Deng, <b>Ruijie Zhu</b>, Yanzhe Liang, Wenfei Yang, Tianzhu Zhang, Xu Zhou
      <br> NeurIPS, 2024
      <br> 
      <a href="https://arxiv.org/abs/2410.13607">[Paper]</a>
      <!-- <a href="">[Webpage]</a> -->
      <a href="https://github.com/peoplelu/DN-4DGS">[Code]</a>
    </td>
  </tr>


  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-plane2depth.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/Plane2Depth">Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation</a>
      <br>Li Liu*, <b>Ruijie Zhu*</b>, Jiacheng Deng, Ziyang Song, Wenfei Yang, Tianzhu Zhang
      <br> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2024
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10711868/">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/plane2depth_page">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth/tree/main/projects/Plane2Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-ScaleDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth: Decomposing Metric Depth Estimation into Scale Prediction and Relative Depth Estimation</a>
      <br><b>Ruijie Zhu</b>, Chuxin Wang, Ziyang Song, Li Liu, Tianzhu Zhang, Yongdong Zhang
      <br> Arxiv, 2024
      <br> 
      <a href="https://arxiv.org/abs/2407.08187">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ScaleDepth">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth/tree/main/projects/ScaleDepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://github.com/RuijieZhu94/TI-Face">TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</a>
      <br><b>Ruijie Zhu</b>, Jiahao Chang, Ziyang Song, Jiahuan Yu, Tianzhu Zhang
      <br> 1st place solution in the View Synthesis Challenge for Human Heads (VSCHH) @ ICCV, 2023
      <br> 
      <a href="https://arxiv.org/abs/2312.09527">[Paper]</a>
      <a href="https://youtu.be/QRuVvtpoeVM">[Video]</a>
      <a href="https://github.com/RuijieZhu94/TI-Face">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-arxiv-ECDepth.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/ECDepth_page/">EC-Depth: Exploring the consistency of self-supervised monocular depth estimation under challenging scenes</a>
      <br>Ziyang Song*, <b>Ruijie Zhu*</b>, Chuxin Wang, Jiacheng Deng, Jianfeng He, Tianzhu Zhang
      <br> ArXiv, 2023
      <br> 
      <a href="http://arxiv.org/abs/2310.08044">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ERDepth_page/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/EC-Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-tcsvt-HABins.jpg" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation across Multiple Datasets</a>
      <br><b>Ruijie Zhu</b>, Ziyang Song, Li Liu, Jianfeng He, Tianzhu Zhang, Yongdong Zhang
      <br> IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2023
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10325550">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/HABins">[Code]</a>
    </td>
  </tr>


</table>

## Talks

<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-motiongs-video.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://www.youtube.com/watch?v=25DgViuuKFI">MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</a>
      <br>Poster session: East Exhibit Hall A-C #1203
      <br>Vancouver @ NeurIPS, 2024
      <!-- <br>  -->
      <!-- <a href="https://arxiv.org/abs/2410.07707">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/MotionGS_page">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/MotionGS">[Code]</a>
      <a href="https://www.youtube.com/watch?v=25DgViuuKFI">[Video]</a> -->
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://youtu.be/QRuVvtpoeVM">TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</a>
      <br>"To NeRF or not to NeRF: A View Synthesis Challenge for Human Heads" workshop
      <br> Paris @ ICCV, 2023
      <!-- <br> 
      <a href="https://arxiv.org/abs/2312.09527">[Paper]</a>
      <a href="https://youtu.be/QRuVvtpoeVM">[Video]</a>
      <a href="https://github.com/RuijieZhu94/TI-Face">[Code]</a>
      <a href="https://sites.google.com/view/vschh/home">[Challenge]</a> -->
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-icraw-IRUDepth.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767">IRUDepth: Improve Robustness and Uncertainty of Self-Supervised Monocular Depth Estimation</a>
      <br>"RoboDepth: The 1st Challenge on Robust Depth Estimation under Corruptions" workshop
      <br> London @ ICRA, 2023
      <!-- <br> 
      <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767">[Video]</a>
      <a href="https://robodepth.github.io/">[Challenge]</a> -->
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2022-eccvw-MixBins.png" style="vertical-align:middle"/>
    </td>
    <td style="align-items:center; border: none;">
      <a href="https://youtu.be/8ZwiSUYNJiI">MixBins: Group-wise Bins for Robust Monocular Depth Estimation via Mixing Datasets</a>
      <br>"Robust Vision Challenge" workshop
      <br> Tel Aviv @ ECCV, 2022
      <!-- <br> 
      <a href="https://youtu.be/8ZwiSUYNJiI">[Video]</a>
      <a href="http://www.robustvision.net/index.php">[Challenge]</a> -->
    </td>
  </tr>

</table>

## Awards

- Wuyajun Scholarship & first class scholarship of NWPU, 2019
- Wuyajun Scholarship & first class scholarship of NWPU, 2020
- CATIC Scholarship (the highest scholarship for graduates, <1%) & first class scholarship of NWPU, 2021
- Outstanding Graduate of NWPU, 2022
- USTC-Suzhou Industrial Park Scholarship & first class scholarship of USTC, 2023
- Deep Space Exploration Scholarship, 2024
- National Scholarship of China, 2024

## Posts

- VALSE•2021 meeting record. [[Yuque]](https://www.yuque.com/docs/share/99290803-dfd7-4343-9ee6-0887f10bcec0?#) [[Zhihu]](https://zhuanlan.zhihu.com/p/422911676)
- Course Notes of Statistical Learning course in USTC. [[Git repo]](https://github.com/RuijieZhu94/StatisticalLearning_USTC) [[Zhihu]](https://www.zhihu.com/question/49386395/answer/3121492954) [[PDF]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/outline.pdf)
 [[Abstract]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/cheatsheet.pdf)

## Others

- Reviewer: ICRA 2023, ICLR 2024, CVPR 2025, ICCV 2025, NeurIPS 2025


<!-- <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM"></script> -->
<!-- <script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=300&t=n&d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM'></script> -->

<div style="text-align: center;">
  <div id="clustr_globe_container" style="display: inline-block; width: 150px; height: 150px;">
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM"></script>
  </div>
</div>
