---
permalink: /
title: "Ruijie Zhu Êú±ÁùøÊù∞"
excerpt: "About me"
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

## Biography

I obtained my Master's degree from the University of Science and Technology of China (USTC) in 2025, where I was advised by Prof. [Yongdong Zhang](https://scholar.google.com/citations?user=hxGs4ukAAAAJ&hl) and Prof. [Tianzhu Zhang](http://staff.ustc.edu.cn/~tzzhang/). Prior to that, I received my B.Eng. degree in Computer Science and Technology from Northwestern Polytechnical University (NWPU) in 2022, under the guidance of Prof. [Yuchao Dai](https://scholar.google.com/citations?user=fddAbqsAAAAJ&hl).

My research interests lie in 3D Computer Vision, with a particular focus on:
*   3D Gaussian Splatting & Neural Rendering
*   Monocular Depth Estimation

## Recent News

<div style="border: 1px solid #ddd; padding: 10px; height: 220px; overflow-y: scroll; border-radius: 5px; background-color: #f9f9f9;">
  <ul style="padding-left: 20px;">
    <li>Nov. 2025: <a href="https://hanzhichang.github.io/meshsplat_web/">MeshSplat</a> was accepted by AAAI 2026.</li>
    <li>Jun. 2025: <a href="https://ruijiezhu94.github.io/ObjectGS_page/">ObjectGS</a> was accepted by ICCV 2025.</li>
    <li>Jun. 2025: Graduated from USTC! üéì</li>
    <li>Jan. 2025: <a href="https://indu1ge.github.io/DepthMaster_page/">DepthMaster</a> was released on arXiv.</li>
    <li>Oct. 2024: <a href="https://ruijiezhu94.github.io/plane2depth_page/">Plane2Depth</a> was accepted by IEEE TCSVT.</li>  
    <li>Sep. 2024: Two papers, <a href="https://ruijiezhu94.github.io/MotionGS_page">MotionGS</a> and <a href="https://arxiv.org/abs/2410.13607">DN-4DGS</a>, were accepted by NeurIPS 2024.</li>
    <li>Jul. 2024: <a href="https://ruijiezhu94.github.io/ScaleDepth">ScaleDepth</a> was released on arXiv.</li>
    <li>Dec. 2023: <a href="https://arxiv.org/abs/2312.09527">TI-Face</a> was released on arXiv.</li>
    <li>Nov. 2023: <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023">HA-Bins</a> was accepted by IEEE TCSVT.</li>
    <li>Oct. 2023: <a href="https://ruijiezhu94.github.io/ERDepth_page">EC-Depth</a> was released on arXiv.</li>
    <li>Oct. 2023: Won the 1st Place in ICCV 2023 workshop: <a href="https://sites.google.com/view/vschh/home">To NeRF or not to NeRF</a>. <a href="https://openaccess.thecvf.com/content/ICCV2023W/RHWC/papers/Jang_VSCHH_2023_A_Benchmark_for_the_View_Synthesis_Challenge_of_ICCVW_2023_paper.pdf">[paper]</a> <a href="https://youtu.be/QRuVvtpoeVM">[video]</a></li>
    <li>June 2023: Won the 1st Place on RoboDepth (Track 1) and 2nd Place (Track 2) at ICRA 2023. <a href="https://arxiv.org/pdf/2307.15061">[paper]</a> <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767">[video]</a></li>
    <li>Oct. 2022: Won the 2nd Place on Monocular Depth Estimation leaderboard in ECCV 2022 workshop: <a href="http://www.robustvision.net/leaderboard.php?benchmark=depth">Robust Vision Challenge 2022</a>. <a href="https://youtu.be/8ZwiSUYNJiI">[video]</a></li>
  </ul>
</div>

## Experiences

*   May 2025 - Present: Research Intern, Tencent ARC Lab
*   Aug. 2024 - Mar. 2025: Research Intern, Shanghai AI Lab
*   Sept. 2022 - Jun. 2025: M.S. Student, USTC
*   Sept. 2018 - July 2022: Undergraduate Student, Honors College, NWPU

<div class="logo" style="display: flex; justify-content: space-around; align-items: center; margin-top: 20px;">
  <a href="https://en.nwpu.edu.cn/"><img src="images/logo_NWPU.png" alt="NWPU" style="height: 80px; width: auto;"></a>
  <a href="https://en.ustc.edu.cn/"><img src="images/logo_USTC.png" alt="USTC" style="height: 80px; width: auto;"></a>
  <a href="https://www.shlab.org.cn/"><img src="images/logo_AILab.jpeg" alt="Shanghai AILab" style="height: 100px; width: auto;"></a>
  <a href="https://arc.tencent.com/en/index"><img src="images/logo_ARCLab.png" alt="Tencent ARCLab" style="height: 40px; width: auto;"></a>
</div>

## Publications
<small>
\* denotes equal contribution. Full list available on <a href="https://scholar.google.com/citations?user=6uuAEdkAAAAJ&hl=en">Google Scholar</a>.
</small>

### 3D Gaussian Splatting & Neural Rendering

<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2025-arxiv-meshsplat.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://hanzhichang.github.io/meshsplat_web/"><b>MeshSplat: Generalizable Sparse-View Surface Reconstruction via Gaussian Splatting</b></a>
      <br>Hanzhi Chang*, <b>Ruijie Zhu*</b>, Wenjie Chang, Mulin Yu, Yanzhe Liang, Jiahao Lu, Zhuoyuan Li, Tianzhu Zhang
      <br> AAAI 2026
      <br> 
      <a href="http://arxiv.org/abs/2508.17811">[Paper]</a>
      <a href="https://hanzhichang.github.io/meshsplat_web/">[Webpage]</a>
      <a href="https://github.com/HanzhiChang/MeshSplat">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2025-iccv-objectgs.jpg" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/ObjectGS_page/"><b>ObjectGS: Object-aware Scene Reconstruction and Scene Understanding via Gaussian Splatting</b></a>
      <br><b>Ruijie Zhu</b>, Mulin Yu, Linning Xu, Lihan Jiang, Yixuan Li, Tianzhu Zhang, Jiangmiao Pang, Bo Dai
      <br> ICCV 2025
      <br> 
      <a href="http://arxiv.org/abs/2507.15454">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ObjectGS_page/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/ObjectGS">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-motiongs.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/MotionGS_page"><b>MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</b></a>
      <br><b>Ruijie Zhu*</b>, Yanzhe Liang*, Hanzhi Chang, Jiacheng Deng, Jiahao Lu, Wenfei Yang, Tianzhu Zhang, Yongdong Zhang
      <br> NeurIPS 2024
      <br> 
      <a href="https://arxiv.org/abs/2410.07707">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/MotionGS_page">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/MotionGS">[Code]</a>
      <a href="https://www.youtube.com/watch?v=25DgViuuKFI">[Video]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-dn4dgs.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://arxiv.org/abs/2410.13607"><b>DN-4DGS: Denoised Deformable Network with Temporal-Spatial Aggregation for Dynamic Scene Rendering</b></a>
      <br>Jiahao Lu, Jiacheng Deng, <b>Ruijie Zhu</b>, Yanzhe Liang, Wenfei Yang, Tianzhu Zhang, Xu Zhou
      <br> NeurIPS 2024
      <br> 
      <a href="https://arxiv.org/abs/2410.13607">[Paper]</a>
      <a href="https://github.com/peoplelu/DN-4DGS">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://github.com/RuijieZhu94/TI-Face"><b>TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</b></a>
      <br><b>Ruijie Zhu</b>, Jiahao Chang, Ziyang Song, Jiahuan Yu, Tianzhu Zhang
      <br> ICCVW 2023 (1st Place in VSCHH Challenge)
      <br> 
      <a href="https://arxiv.org/abs/2312.09527">[Paper]</a>
      <a href="https://youtu.be/QRuVvtpoeVM">[Video]</a>
      <a href="https://github.com/RuijieZhu94/TI-Face">[Code]</a>
    </td>
  </tr>

</table>

### Monocular Depth Estimation

<table style="border-collapse: collapse; border: none;">

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2025-arxiv-depthmaster.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://indu1ge.github.io/DepthMaster_page/"><b>DepthMaster: Taming Diffusion Models for Monocular Depth Estimation</b></a>
      <br>Ziyang Song*, Zerong Wang*, Bo Li, Hao Zhang, <b>Ruijie Zhu</b>, Li Liu, Peng-Tao Jiang, Tianzhu Zhang
      <br> <em>arXiv preprint</em>, 2024
      <br> 
      <a href="https://arxiv.org/abs/2501.02576">[Paper]</a>
      <a href="https://indu1ge.github.io/DepthMaster_page/">[Webpage]</a>
      <a href="https://github.com/indu1ge/DepthMaster">[Code]</a>
      <a href="https://huggingface.co/zysong212/DepthMaster">[Model]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-plane2depth.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/Plane2Depth"><b>Plane2Depth: Hierarchical Adaptive Plane Guidance for Monocular Depth Estimation</b></a>
      <br>Li Liu*, <b>Ruijie Zhu*</b>, Jiacheng Deng, Ziyang Song, Wenfei Yang, Tianzhu Zhang
      <br> IEEE TCSVT 2024
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10711868/">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/plane2depth_page">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth/tree/main/projects/Plane2Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-arxiv-ScaleDepth.jpg" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/ScaleDepth"><b>ScaleDepth: Decomposing Metric Depth Estimation into Scale Prediction and Relative Depth Estimation</b></a>
      <br><b>Ruijie Zhu</b>, Chuxin Wang, Ziyang Song, Li Liu, Tianzhu Zhang, Yongdong Zhang
      <br> <em>arXiv preprint</em>, 2024
      <br> 
      <a href="https://arxiv.org/abs/2407.08187">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ScaleDepth">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/mmdepth/tree/main/projects/ScaleDepth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-arxiv-ECDepth.jpg" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/ERDepth_page/"><b>ER-Depth: Enhancing the Robustness of Self-Supervised Monocular Depth Estimation in Challenging Scenes</b></a>
      <br>Ziyang Song*, <b>Ruijie Zhu*</b>, Chuxin Wang, Jiacheng Deng, Jianfeng He, Tianzhu Zhang
      <br> ACM TOMM 2025
      <br> 
      <a href="http://arxiv.org/abs/2310.08044">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/ERDepth_page/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/EC-Depth">[Code]</a>
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-tcsvt-HABins.jpg" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/"><b>HA-Bins: Hierarchical Adaptive Bins for Robust Monocular Depth Estimation across Multiple Datasets</b></a>
      <br><b>Ruijie Zhu</b>, Ziyang Song, Li Liu, Jianfeng He, Tianzhu Zhang, Yongdong Zhang
      <br> IEEE TCSVT 2023
      <br> 
      <a href="https://ieeexplore.ieee.org/document/10325550">[Paper]</a>
      <a href="https://ruijiezhu94.github.io/HABins_TCSVT2023/">[Webpage]</a>
      <a href="https://github.com/RuijieZhu94/HABins">[Code]</a>
    </td>
  </tr>

</table>

## Talks

<table style="border-collapse: collapse; border: none;">
  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2024-nips-motiongs-video.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://www.youtube.com/watch?v=25DgViuuKFI"><b>MotionGS: Exploring Explicit Motion Guidance for Deformable 3D Gaussian Splatting</b></a>
      <br>Poster session: East Exhibit Hall A-C #1203
      <br>NeurIPS 2024, Vancouver
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-iccvw-TI-Face.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://youtu.be/QRuVvtpoeVM"><b>TIFace: Improving Facial Reconstruction through Tensorial Radiance Fields and Implicit Surfaces</b></a>
      <br>"To NeRF or not to NeRF" Workshop
      <br>ICCV 2023, Paris
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2023-icraw-IRUDepth.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://youtu.be/C97J5SDXmZc?list=PLxxrIfcH-qBGZ6x_e1AT2_YnAxiHIKtkB&t=2767"><b>IRUDepth: Improve Robustness and Uncertainty of Self-Supervised Monocular Depth Estimation</b></a>
      <br>"RoboDepth" Workshop
      <br>ICRA 2023, London
    </td>
  </tr>

  <tr style="border: none;">
    <td style="align-items:center; width: 25%; border: none;">
      <img src="images/2022-eccvw-MixBins.png" style="vertical-align:middle; width: 100%; object-fit: cover;"/>
    </td>
    <td style="align-items:center; border: none; padding-left: 20px;">
      <a href="https://youtu.be/8ZwiSUYNJiI"><b>MixBins: Group-wise Bins for Robust Monocular Depth Estimation via Mixing Datasets</b></a>
      <br>"Robust Vision Challenge" Workshop
      <br>ECCV 2022, Tel Aviv
    </td>
  </tr>
</table>

## Awards

*   Outstanding Graduate of USTC, 2025
*   National Scholarship of China, 2024
*   Deep Space Exploration Scholarship, 2024
*   USTC-Suzhou Industrial Park Scholarship & First Class Scholarship of USTC, 2023
*   Outstanding Graduate of NWPU, 2022
*   CATIC Scholarship (Top 1% scholarship for graduates) & First Class Scholarship of NWPU, 2021
*   Wuyajun Scholarship & First Class Scholarship of NWPU, 2019, 2020

## Academic Services

*   Conference Reviewer: CVPR, ICCV, ECCV, NeurIPS, ICLR, ICRA, 3DV
*   Journal Reviewer: IJCV, IEEE TCSVT, IEEE TMM

## Posts

*   VALSE‚Ä¢2021 meeting record. [[Yuque]](https://www.yuque.com/docs/share/99290803-dfd7-4343-9ee6-0887f10bcec0?#) [[Zhihu]](https://zhuanlan.zhihu.com/p/422911676)
*   Course Notes of Statistical Learning course in USTC. [[Git repo]](https://github.com/RuijieZhu94/StatisticalLearning_USTC) [[Zhihu]](https://www.zhihu.com/question/49386395/answer/3121492954) [[PDF]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/outline.pdf) [[Abstract]](https://github.com/RuijieZhu94/StatisticalLearning_USTC/releases/download/v1.0/cheatsheet.pdf)

<div style="text-align: center;">
  <br>
  <div id="clustr_globe_container" style="display: inline-block; width: 150px; height: 150px;">
    <script type="text/javascript" id="clstr_globe" src="//clustrmaps.com/globe.js?d=QX_iyI0zlBx07-CIFxMa5gP8MwYnoZjUFm6acc6v2DM"></script>
  </div>
</div>